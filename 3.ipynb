{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import time\n",
    "import shutil\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import math\n",
    "import json\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import *\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Convolution2D, Flatten, MaxPooling2D, Lambda, ELU\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "columns = ['center', 'left', 'right', 'steering_angle', 'throttle', 'brake', 'speed']\n",
    "data = pd.read_csv('driving_log.csv', names=columns)\n",
    "\n",
    "print(\"Dataset Columns:\", columns, \"\\n\")\n",
    "print(\"Shape of the dataset:\", data.shape, \"\\n\")\n",
    "print(data.describe(), \"\\n\")\n",
    "\n",
    "print(\"Data loaded...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get randomized datasets for training and validation\n",
    "\n",
    "# shuffle data\n",
    "data = data.reindex(np.random.permutation(data.index))\n",
    "\n",
    "num_train = int((len(data) / 10.) * 9.)\n",
    "\n",
    "X_train = data.iloc[:num_train]\n",
    "X_validation = data.iloc[num_train:]\n",
    "\n",
    "print(\"X_train has {} elements.\".format(len(X_train)))\n",
    "print(\"X_valid has {} elements.\".format(len(X_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# image augmentation variables\n",
    "CAMERA_OFFSET = 0.25\n",
    "CHANNEL_SHIFT_RANGE = 0.2\n",
    "WIDTH_SHIFT_RANGE = 100\n",
    "HEIGHT_SHIFT_RANGE = 40\n",
    "\n",
    "# processed image variables\n",
    "PROCESSED_IMG_COLS = 64\n",
    "PROCESSED_IMG_ROWS = 64\n",
    "PROCESSED_IMG_CHANNELS = 3\n",
    "\n",
    "# model training variables\n",
    "NB_EPOCH = 8\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flip images horizontally\n",
    "def horizontal_flip(img, steering_angle):\n",
    "    flipped_image = cv2.flip(img, 1)\n",
    "    steering_angle = -1 * steering_angle\n",
    "    return flipped_image, steering_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# shift range for each channels\n",
    "def channel_shift(img, channel_shift_range=CHANNEL_SHIFT_RANGE):\n",
    "    img_channel_index = 2 # tf indexing\n",
    "    channel_shifted_image = random_channel_shift(img, channel_shift_range, img_channel_index)\n",
    "    return channel_shifted_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shift height/width of the image by a small fraction\n",
    "def height_width_shift(img, steering_angle):\n",
    "    rows, cols, channels = img.shape\n",
    "    \n",
    "    # Translation\n",
    "    tx = WIDTH_SHIFT_RANGE * np.random.uniform() - WIDTH_SHIFT_RANGE / 2\n",
    "    ty = HEIGHT_SHIFT_RANGE * np.random.uniform() - HEIGHT_SHIFT_RANGE / 2\n",
    "    steering_angle = steering_angle + tx / WIDTH_SHIFT_RANGE * 2 * .2\n",
    "    \n",
    "    transform_matrix = np.float32([[1, 0, tx],\n",
    "                                   [0, 1, ty]])\n",
    "    \n",
    "    translated_image = cv2.warpAffine(img, transform_matrix, (cols, rows))\n",
    "    return translated_image, steering_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def brightness_shift(img, bright_value=None):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    if bright_value:\n",
    "        img[:,:,2] += bright_value\n",
    "    else:\n",
    "        random_bright = .25 + np.random.uniform()\n",
    "        img[:,:,2] = img[:,:,2] * random_bright\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_HSV2RGB)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# crop the top 1/5 of the image to remove the horizon and the bottom 25 pixels to remove the carâ€™s hood\n",
    "def crop_resize_image(img):\n",
    "    shape = img.shape\n",
    "    img = img[math.floor(shape[0]/5):shape[0]-25, 0:shape[1]]\n",
    "    img = cv2.resize(img, (PROCESSED_IMG_COLS, PROCESSED_IMG_ROWS), interpolation=cv2.INTER_AREA)    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_random_transformation(img, steering_angle):\n",
    "    \n",
    "    transformed_image, steering_angle = height_width_shift(img, steering_angle)\n",
    "    transformed_image = brightness_shift(transformed_image)\n",
    "    # transformed_image = channel_shift(transformed_image) # increasing train time. not much benefit. commented\n",
    "    \n",
    "    if np.random.random() < 0.5:\n",
    "        transformed_image, steering_angle = horizontal_flip(transformed_image, steering_angle)\n",
    "            \n",
    "    transformed_image = crop_resize_image(transformed_image)\n",
    "    \n",
    "    return transformed_image, steering_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(fn):\n",
    "    img = load_img(fn)\n",
    "    img = img_to_array(img) \n",
    "    return img\n",
    "\n",
    "test_fn = \"IMG/center_2016_12_01_13_32_43_457.jpg\"\n",
    "steering_angle = 0.0617599\n",
    "\n",
    "test_image = read_image(test_fn)\n",
    "\n",
    "plt.subplots(figsize=(5, 18))\n",
    "\n",
    "# original image\n",
    "plt.subplot(611)\n",
    "plt.xlabel(\"Original Test Image, Steering angle: \" + str(steering_angle))\n",
    "plt.imshow(array_to_img(test_image))\n",
    "\n",
    "# horizontal flip augmentation\n",
    "flipped_image, new_steering_angle = horizontal_flip(test_image, steering_angle)\n",
    "plt.subplot(612)\n",
    "plt.xlabel(\"Horizontally Flipped, New steering angle: \" + str(new_steering_angle))\n",
    "plt.imshow(array_to_img(flipped_image))\n",
    "\n",
    "# channel shift augmentation\n",
    "channel_shifted_image = channel_shift(test_image, 255)\n",
    "plt.subplot(613)\n",
    "plt.xlabel(\"Random Channel Shifted, Steering angle: \" + str(steering_angle))\n",
    "plt.imshow(array_to_img(channel_shifted_image))\n",
    "\n",
    "# width shift augmentation\n",
    "width_shifted_image, new_steering_angle = height_width_shift(test_image, steering_angle)\n",
    "new_steering_angle = \"{:.7f}\".format(new_steering_angle)\n",
    "plt.subplot(614)\n",
    "plt.xlabel(\"Random HT and WD Shifted, New steering angle: \" + str(new_steering_angle))\n",
    "plt.imshow(array_to_img(width_shifted_image))\n",
    "\n",
    "# brightened image\n",
    "brightened_image = brightness_shift(test_image, 255)\n",
    "plt.subplot(615)\n",
    "plt.xlabel(\"Brightened, Steering angle: \" + str(steering_angle))\n",
    "plt.imshow(array_to_img(brightened_image))\n",
    "\n",
    "# crop augmentation\n",
    "cropped_image = crop_resize_image(test_image)\n",
    "plt.subplot(616)\n",
    "plt.xlabel(\"Cropped and Resized, Steering angle: \" + str(steering_angle))\n",
    "_ = plt.imshow(array_to_img(cropped_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_augment_image(line_data):\n",
    "    i = np.random.randint(3)\n",
    "    \n",
    "    if (i == 0):\n",
    "        path_file = line_data['left'][0].strip()\n",
    "        shift_angle = CAMERA_OFFSET\n",
    "    elif (i == 1):\n",
    "        path_file = line_data['center'][0].strip()\n",
    "        shift_angle = 0.\n",
    "    elif (i == 2):\n",
    "        path_file = line_data['right'][0].strip()\n",
    "        shift_angle = -CAMERA_OFFSET\n",
    "        \n",
    "    steering_angle = line_data['steering_angle'][0] + str(shift_angle)\n",
    "    \n",
    "    img = cv2.imread(C:\\Users\\Maria\\Desktop\\data2\\data\\IMG)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img, steering_angle = apply_random_transformation(img, steering_angle)\n",
    "    return img, steering_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generators in multi-threaded applications is not thread-safe. Hence below:\n",
    "class threadsafe_iter:\n",
    "    \"\"\"Takes an iterator/generator and makes it thread-safe by\n",
    "    serializing call to the `next` method of given iterator/generator.\n",
    "    \"\"\"\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            return self.it.__next__()\n",
    "        \n",
    "def threadsafe_generator(f):\n",
    "    \"\"\"A decorator that takes a generator function and makes it thread-safe.\n",
    "    \"\"\"\n",
    "    def g(*a, **kw):\n",
    "        return threadsafe_iter(f(*a, **kw))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generated_steering_angles = []\n",
    "threshold = 1\n",
    "\n",
    "@threadsafe_generator\n",
    "def generate_batch_data(_data, batch_size = 32):\n",
    "    \n",
    "    batch_images = np.zeros((batch_size, PROCESSED_IMG_ROWS, PROCESSED_IMG_COLS, PROCESSED_IMG_CHANNELS))\n",
    "    batch_steering = np.zeros(batch_size)\n",
    "    \n",
    "    while 1:\n",
    "        for batch_index in range(batch_size):\n",
    "            row_index = np.random.randint(len(_data))\n",
    "            line_data = _data.iloc[[row_index]].reset_index()\n",
    "            \n",
    "            # idea borrowed from Vivek Yadav: Sample images such that images with lower angles \n",
    "            # have lower probability of getting represented in the dataset. This alleviates \n",
    "            # any problems we may ecounter due to model having a bias towards driving straight.\n",
    "            \n",
    "            keep = 0\n",
    "            while keep == 0:\n",
    "                x, y = load_and_augment_image(line_data)\n",
    "                if abs(y) < .1:\n",
    "                    val = np.random.uniform()\n",
    "                    if val > threshold:\n",
    "                        keep = 1\n",
    "                else:\n",
    "                    keep = 1\n",
    "            \n",
    "            batch_images[batch_index] = x\n",
    "            batch_steering[batch_index] = y\n",
    "            generated_steering_angles.append(y)\n",
    "        yield batch_images, batch_steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/127.5 - 1., input_shape=(PROCESSED_IMG_ROWS, PROCESSED_IMG_COLS, PROCESSED_IMG_CHANNELS)))\n",
    "model.add(Convolution2D(16, 8, 8, subsample=(4, 4), border_mode=\"same\", activation='elu', name='Conv1'))\n",
    "model.add(Convolution2D(32, 5, 5, subsample=(2, 2), border_mode=\"same\", activation='elu', name='Conv2'))\n",
    "model.add(Convolution2D(64, 5, 5, subsample=(2, 2), border_mode=\"same\", activation='elu', name='Conv3'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(.2))\n",
    "model.add(ELU())\n",
    "model.add(Dense(512, activation='elu', name='FC1'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(ELU())\n",
    "model.add(Dense(1, name='output'))\n",
    "model.summary()\n",
    "\n",
    "# compile\n",
    "opt = Adam(lr=0.0001)\n",
    "model.compile(optimizer=opt, loss='mse', metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LifecycleCallback(keras.callbacks.Callback):\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        global threshold\n",
    "        threshold = 1 / (epoch + 1)\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        pass\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        print('BEGIN TRAINING')\n",
    "        self.losses = []\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        print('END TRAINING')\n",
    "        \n",
    "# Calculate the correct number of samples per epoch based on batch size\n",
    "def calc_samples_per_epoch(array_size, batch_size):\n",
    "    num_batches = array_size / batch_size\n",
    "    samples_per_epoch = math.ceil(num_batches)\n",
    "    samples_per_epoch = samples_per_epoch * batch_size\n",
    "    return samples_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lifecycle_callback = LifecycleCallback()       \n",
    "\n",
    "train_generator = generate_batch_data(X_train, BATCH_SIZE)\n",
    "validation_generator = generate_batch_data(X_validation, BATCH_SIZE)\n",
    "\n",
    "samples_per_epoch = calc_samples_per_epoch((len(X_train)*3), BATCH_SIZE)\n",
    "nb_val_samples = calc_samples_per_epoch((len(X_validation)*3), BATCH_SIZE)\n",
    "\n",
    "history = model.fit_generator(train_generator, \n",
    "                              validation_data = validation_generator,\n",
    "                              samples_per_epoch = samples_per_epoch, \n",
    "                              nb_val_samples = nb_val_samples,\n",
    "                              nb_epoch = NB_EPOCH, verbose=1,\n",
    "                              callbacks=[lifecycle_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
