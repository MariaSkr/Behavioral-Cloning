{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Dataset: drive-data-2 (10672 records)\n",
      "Dataset: drive-data (1529 records)\n",
      "Loading completed (12201 records from 2 datasets)\n"
     ]
    }
   ],
   "source": [
    "# Read driving data\n",
    "# Catalogs with driving data:\n",
    "drive_data_02 = 'drive-data-2'\n",
    "drive_data = 'drive-data'\n",
    "# Log:\n",
    "driving_log = '/driving_log.csv'\n",
    "\n",
    "datasets = [drive_data_02, drive_data]\n",
    "\n",
    "print('Loading datasets...')\n",
    "samples = []\n",
    "for dataset in datasets:\n",
    "    ds = []\n",
    "    with open(dataset + driving_log) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for line in reader:\n",
    "            ds.append(line)\n",
    "        print('Dataset: {0} ({1} records)'.format(dataset, len(ds)))\n",
    "        samples.extend(ds)\n",
    "print('Loading completed ({0} records from {1} datasets)'.format(len(samples), len(datasets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training records (no augmentation): 9760\n",
      "Validation records (no augmentation): 2441\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split off 20% of the data to use for a test set.\n",
    "train_samples, validation_samples = train_test_split(samples, test_size = 0.2)\n",
    "print('Training records (no augmentation): {0}'.format(len(train_samples)))\n",
    "print('Validation records (no augmentation): {0}'.format(len(validation_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update path to an image\n",
    "def update_img_path(path):\n",
    "    upd_path = path.split('/')[-3] + '/' + \\\n",
    "               path.split('/')[-2] + '/' + \\\n",
    "               path.split('/')[-1]\n",
    "    return upd_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot row (1x3) of images with titles\n",
    "def plot_row_3(pics, titles):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(0, 3):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.title(titles[i], wrap=True)\n",
    "        plt.imshow(pics[i])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(samples, batch_size = 32):\n",
    "    num_samples = len(samples)\n",
    "    \n",
    "    # Loop forever so the generator never terminates:\n",
    "    show_plot = True\n",
    "    \n",
    "    while 1:\n",
    "        sklearn.utils.shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                # Extract the fourth token (Steering Angle)\n",
    "                angle_center = float(batch_sample[3])\n",
    "\n",
    "                # Create adjusted steering measurements for the side camera images\n",
    "                correction = 0.2                         # parameter to tune:\n",
    "                angle_left = angle_center + correction\n",
    "                angle_right = angle_center - correction\n",
    "\n",
    "                # Read in images from center, left and right cameras\n",
    "                path_center, path_left, path_right = batch_sample[0], batch_sample[1], batch_sample[2]\n",
    "                \n",
    "                # Update path to an images\n",
    "                path_center = update_img_path(path_center)\n",
    "                path_left   = update_img_path(path_left)\n",
    "                path_right  = update_img_path(path_right)\n",
    "                \n",
    "                # Use OpenCV to load an images\n",
    "                #img_center = cv2.imread(path_center)\n",
    "                img_center = cv2.cvtColor(cv2.imread(path_center), cv2.COLOR_BGR2RGB)\n",
    "                #img_left   = cv2.imread(path_left)\n",
    "                img_left   = cv2.cvtColor(cv2.imread(path_left), cv2.COLOR_BGR2RGB)\n",
    "                #img_right  = cv2.imread(path_right)\n",
    "                img_right  = cv2.cvtColor( cv2.imread(path_right), cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                # Plot example of input and augmented images\n",
    "                if show_plot:\n",
    "                    pics = [img_center, img_left, img_right]\n",
    "                    titles = ['Center camera (ang = {0})'.format(angle_center), \n",
    "                              'Left camera (ang = {0})'.format(angle_left), \n",
    "                              'Right camera (ang = {0})'.format(angle_right)]\n",
    "                    plot_row_3(pics, titles)\n",
    "                    pics = [np.fliplr(img_center), np.fliplr(img_left), np.fliplr(img_right)]\n",
    "                    titles = ['Center camera (ang = {0})'.format(-angle_center), \n",
    "                              'Left camera (ang = {0})'.format(-angle_left), \n",
    "                              'Right camera (ang = {0})'.format(-angle_right)]\n",
    "                    plot_row_3(pics, titles)\n",
    "                    show_plot = False\n",
    "\n",
    "                # Add Images and Angles to dataset\n",
    "                images.extend([img_center, img_left, img_right])\n",
    "                angles.extend([angle_center, angle_left, angle_right])\n",
    "\n",
    "            # Data augmentation\n",
    "            aug_images, aug_angles = [], []\n",
    "            for image, angle in zip(images, angles):\n",
    "                aug_images.append(image)\n",
    "                aug_angles.append(angle)\n",
    "                # Flipping Images (horizontally) and invert Steering Angles\n",
    "                aug_images.append(np.fliplr(image))\n",
    "                aug_angles.append(-angle)\n",
    "\n",
    "            # TODO: Trim image to only see section with road\n",
    "            # Convert Images and Steering measurements to NumPy arrays\n",
    "            # (the format Keras requires)\n",
    "            \n",
    "            X_train = np.array(aug_images)\n",
    "            y_train = np.array(aug_angles)\n",
    "            #X_train = np.array(images)\n",
    "            #y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Build the basic neural network to verify that everything is working\n",
    "# Flattened image connected to a single output node. This single output\n",
    "# node will predict steering angle, which makes this a regression network.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Dropout, Cropping2D\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size = 32)\n",
    "validation_generator = generator(validation_samples, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "# pixel_normalized = pixel / 255\n",
    "# pixel_mean_centered = pixel_normalized - 0.5\n",
    "model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape = (160, 320, 3)))\n",
    "model.add(Cropping2D(cropping=((70, 25), (0, 0))))\n",
    "model.add(Convolution2D(24, 5, 5, subsample = (2, 2), activation = \"relu\"))\n",
    "model.add(Convolution2D(36, 5, 5, subsample = (2, 2), activation = \"relu\"))\n",
    "model.add(Convolution2D(48, 5, 5, subsample = (2, 2), activation = \"relu\"))\n",
    "model.add(Convolution2D(64, 3, 3, activation = \"relu\"))\n",
    "model.add(Convolution2D(64, 3, 3, activation = \"relu\"))\n",
    "#model.add(MaxPooling2D())\n",
    "#model.add(Convolution2D(6, 5, 5, activation = \"relu\"))\n",
    "#model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1164))\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Train model with the feature and label arrays.\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Maria\\Miniconda3\\envs\\carnd-term1\\lib\\threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Maria\\Miniconda3\\envs\\carnd-term1\\lib\\threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\Maria\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\engine\\training.py\", line 429, in data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "StopIteration\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-941279ff201c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mnb_val_samples\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_samples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     nb_epoch          = 3)\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    933\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    936\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[0;32m   1526\u001b[0m                                          \u001b[1;34m'(x, y, sample_weight) '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1527\u001b[0m                                          \u001b[1;34m'or (x, y). Found: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1528\u001b[1;33m                                          str(generator_output))\n\u001b[0m\u001b[0;32m   1529\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1530\u001b[0m                         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: None"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator, \n",
    "    samples_per_epoch = len(train_samples) * 6, \n",
    "    validation_data   = validation_generator,\n",
    "    nb_val_samples    = len(validation_samples) * 6, \n",
    "    nb_epoch          = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the train model\n",
    "model.save('model.h5')\n",
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
